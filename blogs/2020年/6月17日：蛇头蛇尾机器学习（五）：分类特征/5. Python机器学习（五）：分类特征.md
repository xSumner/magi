### 1. 简介

我们常使用定性的信息来判断一个观察值的属性，比如按照性别、颜色或者品牌进行分类。有些分类数据没有内在顺序，这些被称为 nominal 类别 ：

- 蓝色、红色、绿色
- 男性、女性
- 香蕉、草莓、苹果

如果一组分类天然拥有内在的顺序性，它就被称为 ordinal ：

- 低、中、高
- 年轻、年迈
- 同意、中立、反对

大部分机器学习算法都要求其输入是数值型的数据，但分类信息常常用一个字符串型的向量或列表示。

计算字符串之间的距离显然是不可能的，因此需要将字符串转换成某种数值形式，这样才能使用欧氏距离等计算公式。

本文会介绍多种将分类数据中包含的信息合理地转换成数值的方法。

### 2. 对 nominal 型分类特征编码

存在一个没有内部顺序的 nominal 型分类特征（例如，苹果、梨、香蕉），利用 scikit-learn 的 LabelBinarizer 对特征进行 one-hot 编码（独热编码）：

```python
# 加载库
import numpy as np
from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer

# 创建特征
feature = np.array([["Texas"],
                    ["California"],
                    ["Texas"],
                    ["Delaware"],
                    ["Texas"]])

# 创建 one-hot 编码器
one_hot = LabelBinarizer()

# 对特征进行 one-hot 编码
one_hot.fit_transform(feature)

# array([[0, 0, 1],
#        [1, 0, 0],
#        [0, 0, 1],
#        [0, 1, 0],
#        [0, 0, 1]])
```

可以使用 classes_ 方法输出分类 ：

```python
# 查看特征的分类
one_hot.classes_

# array(['California', 'Delaware', 'Texas'], dtype='<U10')
```

如果希望对 one-hot 编码进行逆转换，可以使用 inverse_transform ：

```python
# 对 one-hot 编码逆转换
one_hot.inverse_transform(one_hot.transform(feature))

# array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')
```

还可以使用 pandas 对特征进行 one-hot 编码 ：

```python
# 加载库
import pandas as pd

# 创建虚拟变量
pd.get_dummies(feature[:,0])

California Delaware Texas
0 0 0 1
1 1 0 0
2 0 0 1
3 0 1 0
4 0 0 1
```

scikit-learn 还能处理每个观察值有多个分类的情况 ：

```python
# 创建有多个分类的特征
multiclass_feature = [("Texas", "Florida"),
                      ("California","Alabama"),
                      ("Texas", "Florida"),
                      ("Delware", "Florida"),
                      ("Texas", "Alabama")]

# 创建能处理多个分类的 one-hot 编码器
one_hot_multiclass = MultiLabelBinarizer()

# 对特征进行 one-hot 编码
one_hot_multiclass.fit_transform(multiclass_feature)

# array([[0, 0, 0, 1, 1],
#        [1, 1, 0, 0, 0],
#        [0, 0, 0, 1, 1],
#        [0, 0, 1, 1, 0],
#        [1, 0, 0, 0, 1]])
```

可以用 classes_ 方法查看分类 ：

```python
# 查看分类
one_hot_multiclass.classes_

array(['Alabama', 'California', 'Delware', 'Florida', 'Texas'], dtype=object)
```

有人会认为可以给每个分类赋予一个数值型的值（比如， Texas = 1， California = 2），但是由于这些分类没有内在的顺序，使用数值就会错误地赋予分类一个并不存在的顺序。

正确的策略是为每一个分类都创建一个二元特征，这个方法被称为 one-hot 编码（机器学习）或者虚拟变量（统计学）。

在 one-hot 编码中，每一个分类都被当作一个特征，如果特征存在就用 1 表示，否则用 0 表示。通过使用one-hot编码，我们能得到观察值在一个分类中的属性值，并且保留“分类没有顺序”的状态。

在 one-hot 编码之后，最好从结果矩阵中删除一个 one-hot 编码的特征，以避免线性依赖。

### 3. 对 ordinal 分类特征编码

可以使用 pandas 数据帧的 replace 方法将 ordinal 分类特征中的字符串标签转换成相应的数字 ：

```python
# 加载库
import pandas as pd

# 创建特征
dataframe = pd.DataFrame({"Score": ["Low", "Low", "Medium", "Medium", "High"]})

# 创建映射器
scale_mapper = {"Low":1,
                "Medium":2,
                "High":3}

# 使用映射器来替换特征
dataframe["Score"].replace(scale_mapper)

# 0 1
# 1 1
# 2 2
# 3 2
# 4 3
# Name: Score, dtype: int64
```

有一些分类的特征总是有某种天然顺序的，例如李克特量表（Likert scale）：

- 非常同意
- 同意
- 保持中立
- 反对
- 强烈反对

对那些用于机器学习的特征进行编码时，需要将 ordinal 分类转换成数值，同时保留其顺序。最常见的方法就是，创建一个字典，将分类的字符串标签映射为一个数字，然后将其映射在特征上。

在上例中 high 比 low 大三倍，在绝大多数场景下是没有问题的。但是如果分类之间的间隔不相等，就有问题了 ：

```python
dataframe = pd.DataFrame({"Score": ["Low",
                                    "Low",
                                    "Medium",
                                    "Medium",
                                    "High",
                                    "Barely More Than Medium"]})

scale_mapper = {"Low":1,
                "Medium":2,
                "Barely More Than Medium": 3,
                "High":4}

dataframe["Score"].replace(scale_mapper)

# 0 1
# 1 1
# 2 2
# 3 2
# 4 4
# 5 3
# Name: Score, dtype: int64
```

Low（低）和 Medium（中等）之间的距离与 Medium 和 Baraly More Than Medium（比中等稍微多一点点）之间的一样，这就不太准确了。可以重新设置分类所映射的数值 ：

```python
scale_mapper = {"Low":1,
                "Medium":2,
                "Barely More Than Medium": 2.1,
                "High":3}

dataframe["Score"].replace(scale_mapper)

# 0 1.0
# 1 1.0
# 2 2.0
# 3 2.0
# 4 3.0
# 5 2.1
# Name: Score, dtype: float64
```

### 4. 对特征字典编码

使用 DictVectorizer 将一个字典转换成一个特征矩阵：

```python
# 加载库
from sklearn.feature_extraction import DictVectorizer

# 创建一个字典
data_dict = [{"Red": 2, "Blue": 4},
             {"Red": 4, "Blue": 3},
             {"Red": 1, "Yellow": 2},
             {"Red": 2, "Yellow": 2}]

# 创建字典向量化器
dictvectorizer = DictVectorizer(sparse=False)

# 将字典转换成特征矩阵
features = dictvectorizer.fit_transform(data_dict)

# 查看特征矩阵
features

# array([[ 4., 2., 0.],
#        [ 3., 4., 0.],
#        [ 0., 1., 2.],
#        [ 0., 2., 2.]])
```

默认情况下， DictVectorizer 会输出一个稀疏矩阵来存储除 0 以外的元素。如果矩阵很庞大，这么做有助于节省内存。通过指定 sparse=False 能强制 DictVectorizer 输出一个稠密矩阵。

使用 get_feature_names 方法可以获取所生成的特征的名字 ：

```python
# 获取特征的名字
feature_names = dictvectorizer.get_feature_names()

# 查看特征的名字
feature_names

# ['Blue', 'Red', 'Yellow']
```

可以使用 pandas 的数据帧更清楚地查看输出：

```python
# 加载库
import pandas as pd

# 从特征中创建数据帧
pd.DataFrame(features, columns=feature_names)

Blue Red Yellow
0 4.0 2.0 0.0
1 3.0 4.0 0.0
2 0.0 1.0 2.0
3 0.0 2.0 2.0
```

使用 scikit-learn 的 dictvectorizer 就可以实现字典和矩阵之间的转换。在自然语言处理中，这样的场景很常见。

例如，我们有大量文档，对每个文档都用一个字典存放每个词在文档中出现的次数。使用 dictvectorizer 可以很方便地创建一个特征矩阵，其中的每个特征都表示一个词在某个文档中出现的次数 ：

```python
# 为 4 个文档创建词频字典
doc_1_word_count = {"Red": 2, "Blue": 4}
doc_2_word_count = {"Red": 4, "Blue": 3}
doc_3_word_count = {"Red": 1, "Yellow": 2}
doc_4_word_count = {"Red": 2, "Yellow": 2}

# 创建列表
doc_word_counts = [doc_1_word_count,
                   doc_2_word_count,
                   doc_3_word_count,
                   doc_4_word_count]

# 将词频字典列表转换成特征矩阵
dictvectorizer.fit_transform(doc_word_counts)

# array([[ 4., 2., 0.],
#        [ 3., 4., 0.],
#        [ 0., 1., 2.],
#        [ 0., 2., 2.]])
```

如果每个文档实际是图书馆中的一本书，那么可以想象特征矩阵将变得很庞大（那就需要将 sparse 设置为 True 了）。

### 5. 填充缺失的分类值

有一个分类特征中包含缺失值，需要用预测值来填充。最理想的解决方案是训练一个机器学习分类器来预测缺失值，通常会使用 KNN 分类器 ：

```python
# 加载库
import numpy as np
from sklearn.neighbors import KNeighborsClassifier

# 用分类特征创建特征矩阵
X = np.array([[0, 2.10, 1.45],
              [1, 1.18, 1.33],
              [0, 1.22, 1.27],
              [1, -0.21, -1.19]])

# 创建带缺失值的特征矩阵
X_with_nan = np.array([[np.nan, 0.87, 1.31],
                       [np.nan, -0.67, -0.22]])

# 训练 KNN 分类器
clf = KNeighborsClassifier(3, weights='distance')
trained_model = clf.fit(X[:,1:], X[:,0])

# 预测缺失值的分类
imputed_values = trained_model.predict(X_with_nan[:,1:])

# 将所预测的分类和它们的其他特征连接起来
X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))

# 连接两个特征矩阵
np.vstack((X_with_imputed, X))

# array([[ 0. , 0.87, 1.31],
#        [ 1. , -0.67, -0.22],
#        [ 0. , 2.1 , 1.45],
#        [ 1. , 1.18, 1.33],
#        [ 0. , 1.22, 1.27],
#        [ 1. , -0.21, -1.19]])
```

另一个解决方案是用特征中出现次数最多的值来填充缺失值 ：

```python
from sklearn.preprocessing import Imputer

# 连接两个特征矩阵
X_complete = np.vstack((X_with_nan, X))

imputer = Imputer(strategy='most_frequent', axis=0)

imputer.fit_transform(X_complete)

# array([[ 0. , 0.87, 1.31],
#        [ 0. , -0.67, -0.22],
#        [ 0. , 2.1 , 1.45],
#        [ 1. , 1.18, 1.33],
#        [ 0. , 1.22, 1.27],
#        [ 1. , -0.21, -1.19]])
```

当分类特征中存在缺失值的时候，最好的解决方案是利用机器学习算法预测缺失值。将带缺失值的特征作为目标向量，将其他特征作为特征矩阵，就能完成预测。

另外，可以用特征中出现次数最多的分类来填充缺失值。虽然比使用 KNN 效果差一些，但是它能更容易地扩展到大数据集上。不管是哪一种情况，最好都添加一个二元特征来标识观察值中是否包含填充值。

### 6. 处理不均衡分类

处理一个分类极度不均衡的目标向量，通常需要收集更多的数据。如果做不到，就改变评估模型的衡量标准。如果这也不起作用，可以考虑使用嵌入分类权重参数（如果有的话）的模型、下采样或上采样。

为了方便演示，需要创建一些带有不均衡分类的数据。费雪鸢尾花数据集（Fisher’s Iris dataset）包含 3 个均衡的分类，每个分类有 50 个观察值，都标注了花的种类：山鸢尾（Iris setosa）、维吉尼亚鸢尾（Iris virginia）和变色鸢尾（Iris versilocor）。

为了得到不均衡的数据集，我们移除了 40 个山鸢尾的观察值，并将维吉尼亚鸢尾和变色鸢尾的数据合并。解决方案的目的是得到一个二元目标向量，表示一个观察值的分类是否为山鸢尾。最后显示数据中有 10 个观察值是山鸢尾（分类 0），有 100 个观察值不是山鸢尾（分类 1）：

```python
# 加载库
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris

# 加载鸢尾花数据
iris = load_iris()

# 创建特征矩阵
features = iris.data

# 创建目标向量
target = iris.target

# 移除前 40 个观察值
features = features[40:,:]
target = target[40:]

# 创建二元目标向量来标识观察值是否为类别 0
target = np.where((target == 0), 0, 1)

# 查看不均衡的目标向量
target

# array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
```

scikit-learn 的很多算法都提供了一个参数，可以在训练时对分类进行加权，以此抵消分类数据不均衡带来的影响。 RandomForestClassifier 是一个流行的分类算法，它有一个 class_weight 参数。这个参数可以显式地指定想要的分类权重 ：

```python
# 创建权重
weights = {0: .9, 1: 0.1}

# 创建带权重的随机森林分类器
RandomForestClassifier(class_weight=weights)

# RandomForestClassifier(bootstrap=True, class_weight={0: 0.9, 1: 0.1},
#                        criterion='gini', max_depth=None, max_features='auto',
#                        max_leaf_nodes=None, min_impurity_decrease=0.0,
#                        min_impurity_split=None, min_samples_leaf=1,
#                        min_samples_split=2, min_weight_fraction_leaf=0.0,
#                        n_estimators=10, n_jobs=1, oob_score=False, 
#                        random_state=None, verbose=0, warm_start=False)
```

还可以传入参数 balanced，它会自动创建与分类的频数成反比的权重 ：

```python
# 训练一个带均衡分类权重的随机森林分类器
RandomForestClassifier(class_weight="balanced")

# RandomForestClassifier(bootstrap=True, class_weight='balanced',
#                        criterion='gini', max_depth=None, max_features='auto',
#                        max_leaf_nodes=None, min_impurity_decrease=0.0,
#                        min_impurity_split=None, min_samples_leaf=1,
#                        min_samples_split=2, min_weight_fraction_leaf=0.0,
#                        n_estimators=10, n_jobs=1, oob_score=False, 
#                        random_state=None,verbose=0, warm_start=False)
```

另外，对占多数的分类进行下采样和对占少数的分类进行上采样也是不错的方法。在下采样中，从占多数的分类（也就是拥有更多观察值的分类）无放回地随机取出观察值，创建一个观察值数量与占少数的分类相同的子集。例如，如果占少数的分类有 10 个观察值，那么就从占多数的分类中随机无放回地选取 10 个观察值，然后用这 20 个观察值作为数据集。下面是对于不均衡的山鸢尾花数据集所做的具体处理 ：

```python
# 给每个分类的观察值打标签
i_class0 = np.where(target == 0)[0]
i_class1 = np.where(target == 1)[0]

# 确定每个分类的观察值数量
n_class0 = len(i_class0)
n_class1 = len(i_class1)

# 对于每个分类为 0 的观察值，从分类为 1 的数据中进行无放回的随机采样
i_class1_downsampled = np.random.choice(i_class1, size=n_class0, replace=False)

# 将分类为 0 的目标向量和下采样的分类为 1 的目标向量连接起来
np.hstack((target[i_class0], target[i_class1_downsampled]))

# array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])

# 将分类为 0 的特征矩阵和下采样的分类为 1 的特征矩阵连接起来
np.vstack((features[i_class0,:], features[i_class1_downsampled,:]))[0:5]

# array([[ 5. , 3.5, 1.3, 0.3],
#        [ 4.5, 2.3, 1.3, 0.3],
#        [ 4.4, 3.2, 1.3, 0.2],
#        [ 5. , 3.5, 1.6, 0.6],
#        [ 5.1, 3.8, 1.9, 0.4]])
```

另一个选择是对占多数的分类进行上采样。在上采样中，针对占多数的分类，从占少数的分类中进行有放回的随机采样。在最后得到的结果中，占少数的分类和占多数的分类的观察值数量是相同的。上采样和下采样的实现方式相似，只是反转了一下 ：

```python
# 对于每个分类为 1 的观察值，从分类为 0 的数据中进行有放回的随机采样
i_class0_upsampled = np.random.choice(i_class0, size=n_class1, replace=True)

# 将上采样得到的分类为 0 的目标向量和分类为 1 的目标向量连接起来
np.concatenate((target[i_class0_upsampled], target[i_class1]))

# array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
#        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
#        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
#        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
#        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])

# 将上采样得到的分类为 0 的特征矩阵和分类为 1 的特征矩阵连接起来
np.vstack((features[i_class0_upsampled,:], features[i_class1,:]))[0:5]

# array([[ 5. , 3.5, 1.6, 0.6],
#        [ 5. , 3.5, 1.6, 0.6],
#        [ 5. , 3.3, 1.4, 0.2],
#        [ 4.5, 2.3, 1.3, 0.3],
#        [ 4.8, 3. , 1.4, 0.3]])
```

在真实场景中，不均衡的分类到处可见，比如大多数访客都不会单击“购买”按钮，许多癌症也是比较罕见的。因此，处理不均衡分类就成为机器学习中的一个常见任务。

最好的解决方案是收集更多的观察值——尤其是占少数的分类的观察值。但是通常情况下，这是没法做到的，所以我们需要求助于其他手段。

次优的解决方案是选择更适用于评估不均衡数据的标准。准确率（accuracy）常常被作为评估模型性能的标准，但用准确率来评估不均衡的分类是不合适的。例如，如果样本中只有 0.5% 的人得了某种罕见的癌症，那么即便我们的模型预测没有人会得这个癌症，准确率也能达到 99.5%。很明显，这不是我们想要的结果。可以使用更有效的评估标准，包括混淆矩阵、精确度、召回率、 F1 值以及 ROC 曲线。

第 3 个解决方案是在一些分类器模型中使用分类权重参数，这样就能针对不均衡的分类来调整算法。幸运的是，很多 scikit-learn 的分类器都有 class_weight 参数，使用起来很方便。

第 4 和第 5 个解决方案是相关的 ：下采样和上采样。在下采样中，需要从占多数的分类中创建一个子集，其观察值数量与占少数的分类的观察值数量相等。在上采样中，采取有放回的方式对占少数的分类重复采样，以此创建与占多数的分类有相同数量观察值的数据集。到底是采用下采样还是上采样，需要根据场景做决定。通常情况下，应该同时尝试两种方法，看哪一种的效果更好。

